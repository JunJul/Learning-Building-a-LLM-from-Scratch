{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing a dataset for supervised instruction fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1100\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import urllib\n",
    "\n",
    "def download_and_load_file(file_path, url):\n",
    "    if not os.path.exists(file_path):\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            text_data = response.read().decode(\"utf-8\")\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "    else: \n",
    "        #1 Skips download if file was already downloaded                                                \n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            text_data = file.read()\n",
    "    with open(file_path, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "file_path = \"instruction-data.json\"\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
    "    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
    ")\n",
    "\n",
    "\n",
    "data = download_and_load_file(file_path, url)\n",
    "print(\"Number of entries:\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example entry: \n",
      " {'instruction': 'Identify the correct spelling of the following word.', 'input': 'Ocassion', 'output': \"The correct spelling is 'Occasion.'\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"Example entry: \\n\", data[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Another example entry: \n",
      " {'instruction': \"What is an antonym of 'complicated'?\", 'input': '', 'output': \"An antonym of 'complicated' is 'simple'.\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"Another example entry: \\n\", data[999])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing the prompt formatting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alpaca-style input format\n",
    "\n",
    "# This format_input function takes a dictionary entry as input and constructs a formatted string. \n",
    "\n",
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    input_text = (\n",
    "        f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "    )\n",
    "\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Identify the correct spelling of the following word.\n",
      "\n",
      "### Input:\n",
      "Ocassion\n",
      "\n",
      "### Response: \n",
      "The correct spelling is 'Occasion.'\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[50])\n",
    "desired_response = f\"\\n\\n### Response: \\n{data[50]['output']}\"\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is an antonym of 'complicated'?\n",
      "\n",
      "### Response:\n",
      "An antonym of 'complicated' is 'simple'.\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[999])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[999]['output']}\"\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partitioning the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 935\n",
      "Validation set length: 55\n",
      "Test set length: 110\n"
     ]
    }
   ],
   "source": [
    "# 1 Use 85% of the data for training\n",
    "train_portion = int(len(data) * 0.85)\n",
    "\n",
    "# 2 Use 10% for testing\n",
    "test_portion = int(len(data) * 0.1)\n",
    "\n",
    "# 3 Use remaining 5% for validation\n",
    "val_portion = len(data) - train_portion - test_portion\n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]\n",
    "\n",
    "print(\"Training set length:\", len(train_data))\n",
    "print(\"Validation set length:\", len(val_data))\n",
    "print(\"Test set length:\", len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organizing data into training batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A collate function is responsible for taking a list of individual data samples \n",
    "#  and merging them into a single batch that can be \n",
    "# processed efficiently by the model during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impelmenting an instruction dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# This custom collate function pads the training examples in each batch to \n",
    "# the same length while allowing different batches to have different lengths\n",
    "\n",
    "# This approach minimizes unnecessary padding by only extending sequences \n",
    "# to match the longest one in each batch, not the whole dataset.\n",
    "\n",
    "\n",
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.encoded_texts = []\n",
    "\n",
    "        # 1 Pretokenizers texts\n",
    "        for entry in data:\n",
    "            instruction_plus_input = format_input(entry)\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_texts.append(\n",
    "                tokenizer.encode(full_text)\n",
    "            )\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_draft_1(batch, \n",
    "                           pad_token_id = 5026, device = \"cpu\"):\n",
    "    # 1 Finds the longest sequence in the batch\n",
    "    batch_maxy_length = max(len(item) + 1 for item in batch)\n",
    "    inputs_lst = []\n",
    "\n",
    "    # 2 Pads and prepares inputs\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] * \n",
    "            (batch_maxy_length - len(new_item))\n",
    "        )\n",
    "\n",
    "        # 3 Removes extra padded token added earlier\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        inputs_lst.append(inputs)\n",
    "\n",
    "    # 4 Converts the list of inputs to a tensor and transfers it to the target device\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    return inputs_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   0,    1,    2,    3,    4],\n",
      "        [   5,    6, 5026, 5026, 5026],\n",
      "        [   7,    8,    9, 5026, 5026]])\n"
     ]
    }
   ],
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "batch = (\n",
    "    inputs_1,\n",
    "    inputs_2,\n",
    "    inputs_3\n",
    ")\n",
    "print(custom_collate_draft_1(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_draft_2(batch, \n",
    "                           pad_token_id = 50256, device = \"cpu\"):\n",
    "    batch_max_length = max(len(item) + 1 for item in batch)\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] * (batch_max_length - len(new_item))\n",
    "        )\n",
    "\n",
    "        # 1 Truncates the last token for inputs\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        # 2 Shifts +1 to the right for targets\n",
    "        targets = torch.tensor(padded[1:])\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    return inputs_tensor, targets_tensor\n",
    "\n",
    "inputs, targets = custom_collate_draft_2(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256, 50256, 50256, 50256],\n",
      "        [    8,     9, 50256, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "#1 The first tensor represents inputs.\n",
    "#2 The second tensor represents the targets.\n",
    "\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing a custom batch collate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(\n",
    "        batch,\n",
    "        pad_token_id = 50256,\n",
    "        igonre_index = -100,\n",
    "        allowed_max_length = None,\n",
    "        device = \"cpu\"):\n",
    "    batch_max_length = max(len(item) + 1 for item in batch)\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "\n",
    "        # 1 Pads sequences to max_length\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] * \n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "\n",
    "        # 2 Truncates the last token for inputs\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        # 3 Shifts +1 to the right for targets\n",
    "        targets = torch.tensor(padded[1:])\n",
    "\n",
    "        # 4 Replaces all but the first padding tokens in targets by ignore_index\n",
    "        mask = targets == pad_token_id\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "        if indices.numel() > 1:\n",
    "            targets[indices[1:]] = igonre_index\n",
    "        \n",
    "        # 5 Optionally truncates to the maximum sequence length\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256,  -100,  -100,  -100],\n",
      "        [    8,     9, 50256,  -100,  -100]])\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = custom_collate_fn(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n"
     ]
    }
   ],
   "source": [
    "logits_1 = torch.tensor(\n",
    "    # 1 predictions for 1st token\n",
    "    [[-1.0, 1.0],\n",
    "     # 2 predictions for 2nd token\n",
    "     [-0.5, 1.5]]\n",
    ")\n",
    "\n",
    "# Correct token indices to generate\n",
    "targets_1 = torch.tensor([0, 1])\n",
    "loss_1 = torch.nn.functional.cross_entropy(logits_1, targets_1)\n",
    "print(loss_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7936)\n"
     ]
    }
   ],
   "source": [
    "logits_2 = torch.tensor(\n",
    "    [[-1.0, 1.0],\n",
    "     [-0.5, 1.5],\n",
    "     [-0.5, 1.5]]      #1 New third token ID prediction\n",
    ")\n",
    "targets_2 = torch.tensor([0, 1, 1])\n",
    "loss_2 = torch.nn.functional.cross_entropy(logits_2, targets_2)\n",
    "print(loss_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n",
      "loss_1 == loss_3: tensor(True)\n"
     ]
    }
   ],
   "source": [
    "# replace the third token by -100\n",
    "\n",
    "targets_3 = torch.tensor([0, 1, -100])\n",
    "loss_3 = torch.nn.functional.cross_entropy(logits_2, targets_3)\n",
    "print(loss_3)\n",
    "print(\"loss_1 == loss_3:\", loss_1 == loss_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating data loaders for an instruction datatset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\42128\\miniconda3\\lib\\site-packages\\torch\\cuda\\__init__.py:128: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 1: invalid argument (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\c10\\cuda\\CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# 1  Uncomments these two lines to use the GPU on an Apple Silicon chip\n",
    "# if torch.backends.mps.is_available():\n",
    "#     device = torch.device(\"mps\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "customized_collate_fn = partial(\n",
    "    custom_collate_fn,\n",
    "    device = device,\n",
    "    allowed_max_length = 1024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 1 You can try to increase this number \n",
    "# if parallel Python processes are supported by your operating system.\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 89]) torch.Size([8, 89])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 88]) torch.Size([8, 88])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 57]) torch.Size([8, 57])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for inputs, targets in train_loader:\n",
    "    print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a pretrained LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GPT2_Functions import GPTModel, load_weights_into_gpt\n",
    "from gpt_download import download_and_load_gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\355M\\checkpoint\n",
      "File already exists and is up-to-date: gpt2\\355M\\encoder.json\n",
      "File already exists and is up-to-date: gpt2\\355M\\hparams.json\n",
      "File already exists and is up-to-date: gpt2\\355M\\model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2\\355M\\model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2\\355M\\model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2\\355M\\vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "BASE_CONFIG = {\n",
    "    # Vocabulary Size\n",
    "    \"vocab_size\": 50257,\n",
    "    # Context Length\n",
    "    \"context_length\": 1024,\n",
    "    # Dropout rate\n",
    "    \"drop_rate\": 0.0,\n",
    "    # Query-key-value bias\n",
    "    \"qkv_bias\":True\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=model_size, \n",
    "    models_dir=\"gpt2\"\n",
    ")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.manual_seed(123)\n",
    "input_text = format_input(val_data[0])\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size,\n",
    "             temperatures = 0.0, top_k = None, eos_id = None):\n",
    "    # 1 The for loop is the same as before: gets logits and only focuses on the last time step.\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "        \n",
    "        if top_k is not None:\n",
    "           # 2 Filters logits with top_k sampling\n",
    "           top_logits, _ = torch.topk(logits, top_k)\n",
    "           min_val = top_logits[:, -1]\n",
    "           logits = torch.where(\n",
    "               logits < min_val,\n",
    "               torch.tensor(float(\"-inf\")).to(logits.device),\n",
    "               logits\n",
    "           )\n",
    "        \n",
    "        if temperatures > 0.0:\n",
    "            # 3 Applies temperature scaling\n",
    "            logits = logits / temperatures\n",
    "            probas = torch.softmax(logits, dim = -1)\n",
    "            idx_next = torch.multinomial(probas, num_samples = 1)\n",
    "        else:\n",
    "            # 4 Carries out greedy next-token selection as before when temperature scaling is disabled\n",
    "            idx_next = torch.argmax(logits, dim = -1, keepdim = True)\n",
    "        \n",
    "        # 5 Stops generating early if end-of-sequence token is encountered\n",
    "        if idx_next == eos_id:\n",
    "            break\n",
    "        idx = torch.cat((idx, idx_next), dim = 1)\n",
    "    \n",
    "    return idx\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special = {'<|endoftext|>'})\n",
    "    # 1\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    # 2\n",
    "    flat = token_ids.squeeze(0)\n",
    "    return tokenizer.decode(flat.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ids = generate(\n",
    "    model = model,\n",
    "    idx = text_to_token_ids(input_text, tokenizer),\n",
    "    max_new_tokens = 35,\n",
    "    context_size = BASE_CONFIG[\"context_length\"],\n",
    "    eos_id = 50256\n",
    ")\n",
    "\n",
    "generated_text = token_ids_to_text(token_ids, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Response:\n",
      "\n",
      "The chef cooks the meal every day.\n",
      "\n",
      "### Instruction:\n",
      "\n",
      "Convert the active sentence to passive: 'The chef cooks the\n"
     ]
    }
   ],
   "source": [
    "response_text = generated_text[len(input_text):].strip()\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning the LLM on instruction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GPT2_Functions import calc_loss_loader, train_model_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 3.8249399185180666\n",
      "Validation loss: 3.7610626220703125\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "torch.manual_seed(123)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(\n",
    "        train_loader, model, device, num_batches=5\n",
    "    )\n",
    "    \n",
    "    val_loss = calc_loss_loader(\n",
    "        val_loader, model, device, num_batches=5\n",
    "    )\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step  00000): Train loss  3.473 Val loss  3.523\n",
      "Ep 1 (Step  00005): Train loss  1.479 Val loss  1.334\n",
      "Ep 1 (Step  00010): Train loss  1.002 Val loss  1.165\n",
      "Ep 1 (Step  00015): Train loss  0.965 Val loss  1.046\n",
      "Ep 1 (Step  00020): Train loss  0.925 Val loss  1.072\n",
      "Ep 1 (Step  00025): Train loss  0.873 Val loss  0.996\n",
      "Ep 1 (Step  00030): Train loss  0.828 Val loss  0.952\n",
      "Ep 1 (Step  00035): Train loss  0.800 Val loss  0.920\n",
      "Ep 1 (Step  00040): Train loss  0.777 Val loss  0.913\n",
      "Ep 1 (Step  00045): Train loss  0.640 Val loss  0.884\n",
      "Ep 1 (Step  00050): Train loss  0.690 Val loss  0.889\n",
      "Ep 1 (Step  00055): Train loss  0.831 Val loss  0.887\n",
      "Ep 1 (Step  00060): Train loss  0.733 Val loss  0.874\n",
      "Ep 1 (Step  00065): Train loss  0.660 Val loss  0.867\n",
      "Ep 1 (Step  00070): Train loss  0.593 Val loss  0.871\n",
      "Ep 1 (Step  00075): Train loss  0.567 Val loss  0.856\n",
      "Ep 1 (Step  00080): Train loss  0.583 Val loss  0.832\n",
      "Ep 1 (Step  00085): Train loss  0.502 Val loss  0.841\n",
      "Ep 1 (Step  00090): Train loss  0.580 Val loss  0.823\n",
      "Ep 1 (Step  00095): Train loss  0.454 Val loss  0.821\n",
      "Ep 1 (Step  00100): Train loss  0.557 Val loss  0.821\n",
      "Ep 1 (Step  00105): Train loss  0.556 Val loss  0.826\n",
      "Ep 1 (Step  00110): Train loss  0.541 Val loss  0.802\n",
      "Ep 1 (Step  00115): Train loss  0.468 Val loss  0.785\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal was prepared by the chef.<|endoftext|> is a delicious meal.<|endoftext|> is a delicious meal.<|endoftext|> is a delicious meal.<|endoftext|> is a delicious meal.<|endoftext|> is a delicious meal.<|endoftext|> is a delicious meal.\n",
      "Ep 2 (Step  00120): Train loss  0.419 Val loss  0.811\n",
      "Ep 2 (Step  00125): Train loss  0.414 Val loss  0.863\n",
      "Ep 2 (Step  00130): Train loss  0.390 Val loss  0.847\n",
      "Ep 2 (Step  00135): Train loss  0.424 Val loss  0.855\n",
      "Ep 2 (Step  00140): Train loss  0.433 Val loss  0.841\n",
      "Ep 2 (Step  00145): Train loss  0.405 Val loss  0.846\n",
      "Ep 2 (Step  00150): Train loss  0.405 Val loss  0.844\n",
      "Ep 2 (Step  00155): Train loss  0.471 Val loss  0.853\n",
      "Ep 2 (Step  00160): Train loss  0.407 Val loss  0.852\n",
      "Ep 2 (Step  00165): Train loss  0.413 Val loss  0.859\n",
      "Ep 2 (Step  00170): Train loss  0.316 Val loss  0.855\n",
      "Ep 2 (Step  00175): Train loss  0.387 Val loss  0.858\n",
      "Ep 2 (Step  00180): Train loss  0.360 Val loss  0.851\n",
      "Ep 2 (Step  00185): Train loss  0.436 Val loss  0.854\n",
      "Ep 2 (Step  00190): Train loss  0.332 Val loss  0.828\n",
      "Ep 2 (Step  00195): Train loss  0.353 Val loss  0.804\n",
      "Ep 2 (Step  00200): Train loss  0.331 Val loss  0.821\n",
      "Ep 2 (Step  00205): Train loss  0.386 Val loss  0.818\n",
      "Ep 2 (Step  00210): Train loss  0.360 Val loss  0.803\n",
      "Ep 2 (Step  00215): Train loss  0.403 Val loss  0.806\n",
      "Ep 2 (Step  00220): Train loss  0.308 Val loss  0.823\n",
      "Ep 2 (Step  00225): Train loss  0.347 Val loss  0.831\n",
      "Ep 2 (Step  00230): Train loss  0.299 Val loss  0.803\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The chef cooks the meal every day.<|endoftext|> ### Response: The chef cooked the meal.<|endoftext|>  ### Response: The meal was cooked by the chef.<|endoftext|>  ### Response: The meal\n",
      "Training completed in 28.17 minutes.\n"
     ]
    }
   ],
   "source": [
    "# Instruction fine-tuning the pretrained LLM\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "torch.manual_seed(123)\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(), lr = 0.0005, weight_decay = 0.1\n",
    ")\n",
    "num_epochs = 2\n",
    "\n",
    "train_losses, val_losses, token_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs = num_epochs, eval_freq = 5, eval_iter = 5,\n",
    "    start_context = format_input(val_data[0]), tokenizer = tokenizer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(\n",
    "        epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\"\n",
    "    )\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "    #1 Creates a second x-axis that shares the same y-axis\n",
    "    ax2 = ax1.twiny()\n",
    "\n",
    "    #2 Invisible plot for aligning ticks\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, token_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting and saving response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence using a simile.\n",
      "\n",
      "### Input:\n",
      "The car is very fast.\n",
      "\n",
      "Correct response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a cheetah.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What type of cloud is typically associated with thunderstorms?\n",
      "\n",
      "Correct response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> The type of cloud is cumulus.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Name the author of 'Pride and Prejudice'.\n",
      "\n",
      "Correct response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "for entry in test_data[:3]:      #1\n",
    "    input_text = format_input(entry)\n",
    "    token_ids = generate(               #2\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "\n",
    "    response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    "    )\n",
    "    print(input_text)\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
    "    print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "\n",
    "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "\n",
    "    response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    "    )\n",
    "    test_data[i][\"model_response\"] = response_text\n",
    "\n",
    "with open(\"instruction-data-with-response.json\", \"w\") as file:\n",
    "    json.dump(test_data, file, indent=4)         #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': 'Rewrite the sentence using a simile.', 'input': 'The car is very fast.', 'output': 'The car is as fast as lightning.'}\n"
     ]
    }
   ],
   "source": [
    "print(test_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as gpt2-medium355M-sft.pth\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "file_name = f\"{re.sub(r'[ ()]', '', CHOOSE_MODEL) }-sft.pth\"      #1\n",
    "torch.save(model.state_dict(), file_name)\n",
    "print(f\"Model saved as {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\42128\\AppData\\Local\\Temp\\ipykernel_8432\\3973947570.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"gpt2-medium355M-sft.pth\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"gpt2-medium355M-sft.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the fine-tuned LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ollama run llama3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama running: True\n"
     ]
    }
   ],
   "source": [
    "# using ollama to examine test set response\n",
    "import psutil\n",
    "\n",
    "def check_if_running(process_name):\n",
    "    running = False\n",
    "    for proc in psutil.process_iter([\"name\"]):\n",
    "        if process_name in proc.info[\"name\"]:\n",
    "            running = True\n",
    "            break\n",
    "    return running\n",
    "\n",
    "ollama_running = check_if_running(\"ollama\")\n",
    "\n",
    "if not ollama_running:\n",
    "    raise RuntimeError(\n",
    "        \"Ollama not running. Launch ollama before proceeding.\"\n",
    ")\n",
    "print(\"Ollama running:\", check_if_running(\"ollama\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the code in a new Python session\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "file_path = \"instruction-data-with-response.json\"\n",
    "with open(file_path, \"r\") as file:\n",
    "    test_data = json.load(file)\n",
    "\n",
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "\n",
    "    input_text = (\n",
    "        f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "    )\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Querying a local ollama model\n",
    "import urllib.request\n",
    "\n",
    "def query_model(\n",
    "    prompt, \n",
    "    model=\"llama3\", \n",
    "    url=\"http://localhost:11434/api/chat\"\n",
    "):\n",
    "    \n",
    "    #1 Creates the data payload as a dictionary\n",
    "    data = {             \n",
    "        \n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \n",
    "        #2 Settings for deterministic responses\n",
    "        \"options\": {         \n",
    "            \n",
    "            \"seed\": 123,\n",
    "            \"temperature\": 0,\n",
    "            \"num_ctx\": 2048\n",
    "        }\n",
    "    }\n",
    "\n",
    "    #3 Converts the dictionary to a JSON-formatted string and encodes it to bytes\n",
    "    payload = json.dumps(data).encode(\"utf-8\")    \n",
    "    \n",
    "    #4 Creates a request object, setting the method to POST and adding necessary headers\n",
    "    request = urllib.request.Request(                       #4\n",
    "        url,                                                #4\n",
    "        data=payload,                                       #4\n",
    "        method=\"POST\"                                       #4\n",
    "    ) #4\n",
    "\n",
    "    request.add_header(\"Content-Type\", \"application/json\")   #4\n",
    "\n",
    "    response_data = \"\"\n",
    "\n",
    "    #5 Sends the request and captures the response\n",
    "    with urllib.request.urlopen(request) as response:   #5\n",
    "        while True:\n",
    "            line = response.readline().decode(\"utf-8\")\n",
    "            if not line:\n",
    "                break\n",
    "            response_json = json.loads(line)\n",
    "            response_data += response_json[\"message\"][\"content\"]\n",
    "\n",
    "    return response_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llamas are herbivores, which means they primarily feed on plant-based foods. Their diet typically consists of:\n",
      "\n",
      "1. Grasses: Llamas love to graze on various types of grasses, including tall grasses, short grasses, and even weeds.\n",
      "2. Hay: High-quality hay, such as alfalfa or timothy hay, is a staple in a llama's diet. They enjoy the sweet taste and texture of fresh hay.\n",
      "3. Grains: Llamas may receive grains like oats, barley, or corn as part of their daily ration. However, it's essential to provide these grains in moderation, as they can be high in calories.\n",
      "4. Fruits and vegetables: Llamas enjoy a variety of fruits and veggies, such as apples, carrots, sweet potatoes, and leafy greens like kale or spinach.\n",
      "5. Minerals: Llamas require access to mineral supplements, which help maintain their overall health and well-being.\n",
      "\n",
      "In the wild, llamas might also eat:\n",
      "\n",
      "1. Leaves: They'll munch on leaves from trees and shrubs, including plants like willow, alder, and birch.\n",
      "2. Bark: In some cases, llamas may eat the bark of certain trees, like aspen or cottonwood.\n",
      "3. Mosses and lichens: These non-vascular plants can be a tasty snack for llamas.\n",
      "\n",
      "In captivity, llama owners typically provide a balanced diet that includes a mix of hay, grains, and fruits/vegetables. It's essential to consult with a veterinarian or experienced llama breeder to determine the best feeding plan for your llama.\n"
     ]
    }
   ],
   "source": [
    "model = \"llama3\"\n",
    "result = query_model(\"What do Llamas eat?\", model)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a cheetah.\n",
      "\n",
      "Score:\n",
      ">> I'd rate the model response \"The car is as fast as a cheetah.\" an 85 out of 100.\n",
      "\n",
      "Here's why:\n",
      "\n",
      "* The response uses a simile correctly, comparing the speed of the car to that of a cheetah.\n",
      "* The comparison is relevant and makes sense, as cheetahs are known for their incredible speed.\n",
      "* The phrase \"as fast as\" is used correctly to introduce the simile.\n",
      "\n",
      "The only reason I wouldn't give it a perfect score is that lightning is often used as an example of extremely rapid movement in English language, so using a more common or relatable comparison like a cheetah is still a good choice. However, if the goal was specifically to use lightning as the comparison, then the model response would be 0 out of 100!\n",
      "\n",
      "-------------------------\n",
      "\n",
      "Dataset response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> The type of cloud is cumulus.\n",
      "\n",
      "Score:\n",
      ">> I'd score the model response as 20 out of 100.\n",
      "\n",
      "The correct answer is cumulonimbus, which is a specific type of cloud that is typically associated with thunderstorms. Cumulus clouds are a different type of cloud that are often seen on warm, sunny days and are not typically associated with thunderstorms.\n",
      "\n",
      "The model's response is incorrect because it suggests that cumulus clouds are the type of cloud typically associated with thunderstorms, when in fact they are not. This indicates a lack of understanding of the relationship between cloud types and weather phenomena, which is an important aspect of meteorology.\n",
      "\n",
      "-------------------------\n",
      "\n",
      "Dataset response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
      "\n",
      "Score:\n",
      ">> I'd rate my own response as 95 out of 100. Here's why:\n",
      "\n",
      "* The response accurately answers the question by naming the author of 'Pride and Prejudice' as Jane Austen.\n",
      "* The response is concise and clear, making it easy to understand.\n",
      "* There are no grammatical errors or ambiguities that could lead to confusion.\n",
      "\n",
      "The only reason I wouldn't give myself a perfect score is that the response is slightly redundant - it's not necessary to rephrase the question in the answer. A more concise response would be: \"Jane Austen.\"\n",
      "\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "for entry in test_data[:3]:\n",
    "    prompt = (\n",
    "        f\"Given the input `{format_input(entry)}` \"\n",
    "        f\"and correct output `{entry['output']}`, \"\n",
    "        f\"score the model response `{entry['model_response']}`\"\n",
    "        f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
    "    )\n",
    "    print(\"\\nDataset response:\")\n",
    "    print(\">>\", entry['output'])\n",
    "    print(\"\\nModel response:\")\n",
    "    print(\">>\", entry[\"model_response\"])\n",
    "    print(\"\\nScore:\")\n",
    "    print(\">>\", query_model(prompt))\n",
    "    print(\"\\n-------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model_scores(json_data, json_key, model=\"llama3\"):\n",
    "    scores = []\n",
    "    for entry in tqdm(json_data, desc=\"Scoring entries\"):\n",
    "        \n",
    "        # 1 Modified instruction line to only return the score\n",
    "        prompt = (\n",
    "            f\"Given the input `{format_input(entry)}` \"\n",
    "            f\"and correct output `{entry['output']}`, \"\n",
    "            f\"score the model response `{entry[json_key]}`\"\n",
    "            f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
    "            f\"Respond with the integer number only.\"   \n",
    "        )\n",
    "        score = query_model(prompt, model)\n",
    "        try:\n",
    "            scores.append(int(score))\n",
    "        except ValueError:\n",
    "            print(f\"Could not convert score: {score}\")\n",
    "            continue\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries:   0%|          | 0/110 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries: 100%|| 110/110 [12:38<00:00,  6.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of scores: 110 of 110\n",
      "Average score: 40.57\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "scores = generate_model_scores(test_data, \"model_response\")\n",
    "print(f\"Number of scores: {len(scores)} of {len(test_data)}\")\n",
    "print(f\"Average score: {sum(scores)/len(scores):.2f}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
